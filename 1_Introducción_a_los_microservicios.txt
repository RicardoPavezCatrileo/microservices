https://www.nginx.com/blog/introduction-to-microservices/

Introducción a los microservicios
microservicios , aplicación monolítica , Docker , nube

Editor  : esta serie de artículos en siete partes ya está completa:

Introducción a Microservicios (este artículo)
Creación de microservicios: uso de una puerta de enlace API
Building Microservices: comunicación entre procesos en una arquitectura de microservicios
Descubrimiento de servicios en una arquitectura de microservicios
Gestión de datos basada en eventos para microservicios
Elegir una estrategia de implementación de microservicios
Refactorizando un Monolito en Microservicios
También puede descargar el conjunto completo de artículos, además de información sobre la implementación de microservicios utilizando NGINX Plus, como un libro electrónico: Microservicios: del diseño al despliegue . Además, consulte la nueva página de Soluciones de Microservicios .

Actualmente, los microservicios reciben mucha atención: artículos, blogs, debates en las redes sociales y presentaciones de conferencias. Se dirigen rápidamente hacia el pico de expectativas infladas en el ciclo de Gartner Hype . Al mismo tiempo, hay escépticos en la comunidad del software que rechazan los microservicios como algo nuevo. Los detractores afirman que la idea es solo un cambio de nombre de SOA. Sin embargo, a pesar de la exageración y el escepticismo, el patrón de Arquitectura de Microservicios tiene beneficios significativos, especialmente cuando se trata de permitir el desarrollo ágil y la entrega de aplicaciones empresariales complejas.

Esta publicación de blog es la primera de una serie de siete partes sobre diseño, construcción e implementación de microservicios. Aprenderá sobre el enfoque y cómo se compara con el patrón de arquitectura monolítica más tradicional . Esta serie describirá los diversos elementos de una arquitectura de microservicios. Aprenderá sobre los beneficios y las desventajas del patrón de Arquitectura de Microservicios, si tiene sentido para su proyecto y cómo aplicarlo.

Primero veamos por qué debería considerar usar microservicios.

Construyendo Aplicaciones Monolíticas
Imaginemos que estaba comenzando a construir una nueva aplicación de taxi para invocar a Uber y Hailo. Después de algunas reuniones preliminares y la recopilación de requisitos, creará un nuevo proyecto manualmente o mediante un generador que viene con Rails, Spring Boot, Play o Maven. Esta nueva aplicación tendría una arquitectura hexagonal modular , como en el siguiente diagrama:


En el núcleo de la aplicación se encuentra la lógica empresarial, que se implementa mediante módulos que definen servicios, objetos de dominio y eventos. Alrededor del núcleo hay adaptadores que interactúan con el mundo externo. Los ejemplos de adaptadores incluyen componentes de acceso a la base de datos, componentes de mensajería que producen y consumen mensajes, y componentes web que exponen las API o implementan una UI.

A pesar de tener una arquitectura lógica modular, la aplicación se empaqueta y se implementa como un monolito. El formato real depende del lenguaje y el marco de la aplicación. Por ejemplo, muchas aplicaciones Java se empaquetan como archivos WAR y se implementan en servidores de aplicaciones como Tomcat o Jetty. Otras aplicaciones Java se empaquetan como JAR ejecutables independientes. Del mismo modo, las aplicaciones Rails y Node.js se empaquetan como una jerarquía de directorios.

Las aplicaciones escritas en este estilo son extremadamente comunes. Son simples de desarrollar ya que nuestros IDEs y otras herramientas se enfocan en construir una sola aplicación. Este tipo de aplicaciones también son fáciles de probar. Puede implementar pruebas de extremo a extremo simplemente iniciando la aplicación y probando la interfaz de usuario con Selenium. Las aplicaciones monolíticas también son simples de implementar. Solo tiene que copiar la aplicación empaquetada a un servidor. También puede escalar la aplicación ejecutando varias copias detrás de un equilibrador de carga. En las primeras etapas del proyecto, funciona bien.

Marcha hacia el infierno monolítico
Desafortunadamente, este enfoque simple tiene una gran limitación. Las aplicaciones exitosas tienen la costumbre de crecer con el tiempo y, eventualmente, convertirse en enormes. Durante cada sprint, su equipo de desarrollo implementa algunas historias más, lo que, por supuesto, significa agregar muchas líneas de código. Después de unos años, su pequeña y simple aplicación se convertirá en un monolito monstruoso . Para dar un ejemplo extremo, recientemente hablé con un desarrollador que estaba escribiendo una herramienta para analizar las dependencias entre los miles de JAR en su aplicación multimillonaria de código de línea (LOC). Estoy seguro de que tomó el esfuerzo concertado de una gran cantidad de desarrolladores durante muchos años crear tal bestia.

Una vez que su aplicación se ha convertido en un gran monolito complejo, su organización de desarrollo probablemente se encuentre en un mundo de dolor. Cualquier intento de desarrollo ágil y entrega fracasará. Un problema importante es que la aplicación es abrumadoramente compleja. Simplemente es demasiado grande para que cualquier desarrollador lo entienda completamente. Como resultado, corregir errores e implementar nuevas funciones de forma correcta se vuelve difícil y lento. Lo que es más, esto tiende a ser una espiral descendente. Si la base del código es difícil de entender, los cambios no se realizarán correctamente. Terminarás con una gran bola de barro monstruosa e incomprensible .

El gran tamaño de la aplicación también ralentizará el desarrollo. Cuanto mayor sea la aplicación, mayor será el tiempo de inicio. Por ejemplo, en una encuesta reciente, algunos desarrolladores informaron tiempos de puesta en marcha de hasta 12 minutos. También he escuchado anécdotas de aplicaciones que tardan hasta 40 minutos en iniciarse. Si los desarrolladores regularmente tienen que reiniciar el servidor de aplicaciones, entonces una gran parte de su día lo pasarán esperando y su productividad sufrirá.

Otro problema con una aplicación monolítica grande y compleja es que es un obstáculo para la implementación continua. Hoy en día, el estado del arte para las aplicaciones SaaS es impulsar los cambios en la producción muchas veces al día. Esto es extremadamente difícil de hacer con un monolito complejo, ya que debe volver a implementar toda la aplicación para actualizar cualquier parte de ella. Los largos tiempos de puesta en marcha que mencioné anteriormente tampoco ayudarán. Además, dado que el impacto de un cambio generalmente no se entiende muy bien, es probable que tenga que realizar extensas pruebas manuales. En consecuencia, el despliegue continuo es casi imposible de hacer.

Las aplicaciones monolíticas también pueden ser difíciles de escalar cuando diferentes módulos tienen requisitos de recursos conflictivos. Por ejemplo, un módulo podría implementar lógica de procesamiento de imágenes intensivas en CPU e idealmente se implementaría en instancias de Amazon EC2 Compute Optimized . Otro módulo podría ser una base de datos en memoria y el más adecuado para las instancias optimizadas para la memoria EC2 . Sin embargo, debido a que estos módulos se implementan juntos, debe comprometer la elección del hardware.

Otro problema con las aplicaciones monolíticas es la fiabilidad. Debido a que todos los módulos se ejecutan dentro del mismo proceso, un error en cualquier módulo, como una pérdida de memoria, puede reducir todo el proceso. Además, dado que todas las instancias de la aplicación son idénticas, esa falla afectará la disponibilidad de toda la aplicación.

Por último, pero no menos importante, las aplicaciones monolíticas hacen que sea extremadamente difícil adoptar nuevos marcos e idiomas. Por ejemplo, imaginemos que tiene 2 millones de líneas de código escritas utilizando el marco XYZ. Sería extremadamente costoso (tanto en tiempo como en costo) reescribir toda la aplicación para usar el marco ABC más nuevo, incluso si ese marco fuera considerablemente mejor. Como resultado, existe una gran barrera para la adopción de nuevas tecnologías. Estás atrapado con cualquier elección de tecnología que hayas hecho al comienzo del proyecto.

Para resumir: tiene una aplicación crítica para el negocio exitosa que se ha convertido en un monolito monstruoso que muy pocos desarrolladores entienden. Está escrito con tecnología obsoleta e improductiva que dificulta la contratación de desarrolladores con talento. La aplicación es difícil de escalar y no es confiable. Como resultado, el desarrollo ágil y la entrega de aplicaciones es imposible.

Entonces, ¿qué puede hacer usted al respecto?

Microservicios: abordar la complejidad
Muchas organizaciones, como Amazon, eBay y Netflix , han resuelto este problema adoptando lo que ahora se conoce como el patrón de Arquitectura de Microservicios . En lugar de crear una única aplicación monstruosa y monolítica, la idea es dividir su aplicación en un conjunto de servicios más pequeños e interconectados.

Un servicio típicamente implementa un conjunto de características o funcionalidades distintas, tales como gestión de pedidos, gestión de clientes, etc. Cada microservicio es una miniaplicación que tiene su propia arquitectura hexagonal que consiste en lógica comercial junto con varios adaptadores. Algunos microservicios expondrían una API consumida por otros microservicios o por los clientes de la aplicación. Otros microservicios podrían implementar una interfaz de usuario web. En tiempo de ejecución, cada instancia suele ser una VM en la nube o un contenedor Docker.

Por ejemplo, una posible descomposición del sistema descrito anteriormente se muestra en el siguiente diagrama:

Cada área funcional de la aplicación ahora se implementa mediante su propio microservicio. Además, la aplicación web se divide en un conjunto de aplicaciones web más simples (como una para pasajeros y otra para conductores en nuestro ejemplo de taxi). Esto hace que sea más fácil implementar experiencias distintas para usuarios específicos, dispositivos o casos de uso especializados.

Cada servicio back-end expone una API REST y la mayoría de los servicios consumen las API proporcionadas por otros servicios. Por ejemplo, Driver Management usa el servidor de notificaciones para indicarle a un controlador disponible sobre un posible viaje. Los servicios de interfaz de usuario invocan los otros servicios para generar páginas web. Los servicios también pueden usar comunicación asincrónica basada en mensajes. La comunicación entre servicios se tratará con más detalle más adelante en esta serie.

Algunas API REST también están expuestas a las aplicaciones móviles utilizadas por los conductores y los pasajeros. Sin embargo, las aplicaciones no tienen acceso directo a los servicios de back-end. En cambio, la comunicación está mediada por un intermediario conocido como API Gateway . La API Gateway es responsable de tareas tales como el equilibrio de carga, el almacenamiento en caché, el control de acceso, la medición de API y la supervisión, y se puede implementar de manera efectiva utilizando NGINX . Los artículos posteriores de la serie cubrirán la API Gateway .

El patrón de Arquitectura de microservicios corresponde a la escala del eje Y del cubo de escala , que es un modelo 3D de escalabilidad del excelente libro El arte de la escalabilidad . Los otros dos ejes de escala son escalamiento del eje X, que consiste en ejecutar múltiples copias idénticas de la aplicación detrás de un equilibrador de carga, y escalado del eje Z (o partición de datos), donde un atributo de la solicitud (por ejemplo, la clave primaria de una fila o identidad de un cliente) se usa para enrutar la solicitud a un servidor en particular.

Las aplicaciones generalmente usan los tres tipos de escala juntas. La escala del eje Y descompone la aplicación en microservicios como se muestra arriba en la primera figura de esta sección. En tiempo de ejecución, la escala del eje X ejecuta varias instancias de cada servicio detrás de un equilibrador de carga para el rendimiento y la disponibilidad. Algunas aplicaciones también pueden usar la escala del eje Z para dividir los servicios. El siguiente diagrama muestra cómo se podría implementar el servicio Trip Management con Docker ejecutándose en Amazon EC2.


En tiempo de ejecución, el servicio Trip Management consiste en múltiples instancias de servicio. Cada instancia de servicio es un contenedor Docker. Para estar altamente disponibles, los contenedores se ejecutan en múltiples VM en la nube. Delante de las instancias de servicio hay un equilibrador de carga como NGINX que distribuye las solicitudes entre las instancias. El equilibrador de carga también podría manejar otras preocupaciones como el almacenamiento en caché , el control de acceso , la medición de API y la supervisión .

El patrón de Arquitectura de Microservicios tiene un impacto significativo en la relación entre la aplicación y la base de datos. En lugar de compartir un único esquema de base de datos con otros servicios, cada servicio tiene su propio esquema de base de datos. Por un lado, este enfoque está en desacuerdo con la idea de un modelo de datos para toda la empresa. Además, a menudo resulta en la duplicación de algunos datos. Sin embargo, tener un esquema de base de datos por servicio es esencial si desea beneficiarse de los microservicios, ya que asegura un acoplamiento flexible. El siguiente diagrama muestra la arquitectura de la base de datos para la aplicación de ejemplo.


Cada uno de los servicios tiene su propia base de datos. Además, un servicio puede usar un tipo de base de datos que se adapte mejor a sus necesidades, la denominada arquitectura de persistencia políglota. Por ejemplo, Driver Management, que encuentra controladores cercanos a un posible pasajero, debe usar una base de datos que soporte geo-queries eficientes.

En la superficie, el patrón de Arquitectura de Microservicios es similar a SOA. Con ambos enfoques, la arquitectura consiste en un conjunto de servicios. Sin embargo, una forma de pensar sobre el patrón de Arquitectura de Microservicios es que es SOA sin la comercialización y el equipaje percibido de las especificaciones de servicios web (WS- *) y un Enterprise Service Bus (ESB). Las aplicaciones basadas en microservicio favorecen protocolos más simples y livianos, como REST, en lugar de WS- *. También evitan mucho el uso de ESB y en su lugar implementan la funcionalidad similar a ESB en los mismos microservicios. El patrón de Arquitectura de Microservicios también rechaza otras partes de SOA, como el concepto de un esquema canónico.

Los beneficios de los microservicios
El patrón de Arquitectura de Microservicios tiene una serie de beneficios importantes. Primero, aborda el problema de la complejidad. Descompone lo que de otro modo sería una monstruosa aplicación monolítica en un conjunto de servicios. Si bien la cantidad total de funcionalidad no se modifica, la aplicación se ha dividido en fragmentos o servicios manejables. Cada servicio tiene un límite bien definido en forma de una API impulsada por mensajes o RPC. El patrón de Arquitectura de Microservicios impone un nivel de modularidad que en la práctica es extremadamente difícil de lograr con una base de código monolítico. En consecuencia, los servicios individuales son mucho más rápidos de desarrollar y mucho más fáciles de comprender y mantener.

En segundo lugar, esta arquitectura permite que cada servicio se desarrolle de forma independiente por un equipo que se centra en ese servicio. Los desarrolladores son libres de elegir cualquier tecnología que tenga sentido, siempre que el servicio respete el contrato de la API. Por supuesto, la mayoría de las organizaciones querrían evitar la anarquía completa y limitar las opciones tecnológicas. Sin embargo, esta libertad significa que los desarrolladores ya no están obligados a utilizar las tecnologías posiblemente obsoletas que existían al comienzo de un nuevo proyecto. Al escribir un nuevo servicio, tienen la opción de usar la tecnología actual. Además, dado que los servicios son relativamente pequeños, es factible reescribir un servicio antiguo utilizando la tecnología actual.

En tercer lugar, el patrón de Arquitectura de Microservicios permite que cada microservicio se implemente de forma independiente. Los desarrolladores nunca deben coordinar la implementación de cambios que son locales para su servicio. Este tipo de cambios se pueden implementar tan pronto como se prueben. El equipo de UI puede, por ejemplo, realizar pruebas A / B e iterar rápidamente en los cambios de la interfaz de usuario. El patrón de Arquitectura de Microservicios hace posible el despliegue continuo.

Finalmente, el patrón de Arquitectura de Microservicios permite escalar cada servicio de forma independiente. Puede implementar solo el número de instancias de cada servicio que satisfaga sus limitaciones de capacidad y disponibilidad. Además, puede usar el hardware que mejor se adapte a los requisitos de recursos de un servicio. Por ejemplo, puede implementar un servicio de procesamiento de imágenes con uso intensivo de la CPU en instancias de EC2 Compute Optimized y desplegar un servicio de base de datos en memoria en instancias optimizadas para la memoria EC2.

Los inconvenientes de los microservicios
Como escribió Fred Brooks hace casi 30 años, no hay balas de plata. Al igual que cualquier otra tecnología, la arquitectura de Microservicios tiene inconvenientes. Un inconveniente es el nombre en sí mismo. El término microservicio pone énfasis excesivo en el tamaño del servicio. De hecho, hay algunos desarrolladores que abogan por la construcción de servicios extremadamente precisos 10-100 LOC. Si bien los servicios pequeños son preferibles, es importante recordar que son un medio para un fin y no el objetivo principal. El objetivo de microservicios es descomponer suficientemente la aplicación para facilitar el desarrollo y la implementación de aplicaciones ágiles.

Otro inconveniente importante de los microservicios es la complejidad que surge del hecho de que una aplicación de microservicios es un sistema distribuido. Los desarrolladores deben elegir e implementar un mecanismo de comunicación entre procesos basado en mensajería o RPC. Además, también deben escribir código para manejar fallas parciales ya que el destino de una solicitud puede ser lento o no estar disponible. Si bien nada de esto es ciencia de cohetes, es mucho más complejo que en una aplicación monolítica donde los módulos se invocan entre sí a través de llamadas de método / procedimiento de nivel de lenguaje.

Otro desafío con microservicios es la arquitectura de base de datos particionada. Las transacciones comerciales que actualizan varias entidades comerciales son bastante comunes. Este tipo de transacciones son triviales para implementar en una aplicación monolítica porque hay una única base de datos. Sin embargo, en una aplicación basada en microservicios, debe actualizar varias bases de datos propiedad de diferentes servicios. El uso de transacciones distribuidas generalmente no es una opción, y no solo por el teorema CAP . Simplemente no son compatibles con muchas de las bases de datos y corredores de mensajería NoSQL altamente escalables de la actualidad. Terminas teniendo que utilizar un enfoque basado en la coherencia final, que es más desafiante para los desarrolladores.

Probar una aplicación de microservicios también es mucho más complejo. Por ejemplo, con un marco moderno como Spring Boot, es trivial escribir una clase de prueba que inicie una aplicación web monolítica y pruebe su API REST. En contraste, una clase de prueba similar para un servicio necesitaría lanzar ese servicio y cualquier servicio del que dependa (o al menos configurar talones para esos servicios). Una vez más, esto no es ciencia espacial, pero es importante no subestimar la complejidad de hacer esto.

Otro desafío importante con el patrón de Arquitectura de Microservicios es implementar cambios que abarcan múltiples servicios. Por ejemplo, imaginemos que está implementando una historia que requiere cambios en los servicios A, B y C, donde A depende de B y B depende de C. En una aplicación monolítica, puede simplemente cambiar los módulos correspondientes, integrar los cambios, y desplegarlos de una vez. Por el contrario, en un patrón de Arquitectura de Microservicios, debe planificar y coordinar cuidadosamente el despliegue de los cambios en cada uno de los servicios. Por ejemplo, necesitaría actualizar el servicio C, seguido del servicio B y, finalmente, el servicio A. Afortunadamente, la mayoría de los cambios suelen afectar solo a un servicio y los cambios multiservicio que requieren coordinación son relativamente raros.

La implementación de una aplicación basada en microservicios también es mucho más compleja. Una aplicación monolítica simplemente se implementa en un conjunto de servidores idénticos detrás de un equilibrador de carga tradicional. Cada instancia de aplicación se configura con las ubicaciones (host y puertos) de los servicios de infraestructura, como la base de datos y un intermediario de mensajes. Por el contrario, una aplicación de microservicio generalmente consiste en una gran cantidad de servicios. Por ejemplo, Hailo tiene 160 servicios diferentes y Netflix tiene más de 600 según Adrian Cockcroft. Cada servicio tendrá múltiples instancias de tiempo de ejecución. Esas son muchas más partes móviles que deben configurarse, implementarse, escalarse y monitorearse. Además, también deberá implementar un mecanismo de descubrimiento de servicios (discutido en una publicación posterior) que permita a un servicio descubrir las ubicaciones (hosts y puertos) de cualquier otro servicio con el que necesite comunicarse. Los enfoques tradicionales basados ??en tickets y manuales para las operaciones no pueden escalar a este nivel de complejidad. En consecuencia, la implementación exitosa de una aplicación de microservicios requiere un mayor control de los métodos de implementación por parte de los desarrolladores y un alto nivel de automatización.

Un enfoque para la automatización es usar un PaaS estándar como Cloud Foundry . A PaaS proporciona a los desarrolladores una forma fácil de implementar y administrar sus microservicios. Los aísla de preocupaciones tales como la obtención y configuración de recursos de TI. Al mismo tiempo, los profesionales de redes y sistemas que configuran PaaS pueden garantizar el cumplimiento de las mejores prácticas y las políticas de la empresa. Otra forma de automatizar la implementación de microservicios es desarrollar lo que es esencialmente su propio PaaS. Un punto de partida típico es utilizar una solución de clúster, como Kubernetes , junto con una tecnología como Docker. Más adelante en esta serie veremos cómo la entrega de aplicaciones basada en software enfoques como NGINX, que maneja fácilmente el almacenamiento en caché, el control de acceso, la medición de API y la supervisión a nivel de microservicio, pueden ayudar a resolver este problema.

Resumen
Construir aplicaciones complejas es intrínsecamente difícil. Una arquitectura monolítica solo tiene sentido para aplicaciones simples y livianas. Usted terminará en un mundo de dolor si lo usa para aplicaciones complejas. El patrón de arquitectura Microservicios es la mejor opción para aplicaciones complejas y en desarrollo a pesar de los inconvenientes y desafíos de implementación.

En posteriores publicaciones de blog, profundizaré en los detalles de varios aspectos del patrón de Arquitectura de Microservicios y analizaré temas como descubrimiento de servicios, opciones de implementación de servicios y estrategias para refactorizar una aplicación monolítica en los servicios.

Manténganse al tanto






